---
# ResNet options (Don't change these 3 options)
resnet18: false                   # If true, it loads resnet18 architecture
resnet50: false                   # If true, it loads resnet50 architecture
pretrained: false                 # If true, it loads pre-trained resnet models if resnet is being used.

# Any option from here onwards can be changed
# Custom Encoder
conv_dims:                        # Custom architecture for Encoder with convolutional layers, an alternative to resnet.
  - [  1,  32, 5, 2, 1, 1]        # i=input channel, o=output channel, k = kernel, s = stride, p = padding, d = dilation
  - [ 32, 128, 5, 2, 1, 1]        # [i, o, k, s, p, d]
  - [128, 512, 5, 2, 1, 1]        # [i, o, k, s, p, d]
  - 512                           # Dimension of bottleneck layer

# Batchnorm & Dropout
isBatchNorm: false                # Set True to use BatchNorm layer
isDropout: false                  # Set True to use Dropout layer

# Hyper-parameters
learning_rate: 0.001              # Learning rate for training
dropout_rate: 0.5                 # Set dropout rate if Dropout is being used
tau: 0.1                          # temperature parameter used in NTXentLoss
batch_size: 512                   # Set batch size
epochs: 100                       # Number of epochs to use for training
scheduler: false                  # If true, it will use scheduler for learning rate

# Normalisation and Objective func.
cosine_similarity: False          # If True, use cosine similarity in NTXentLoss. Else, use dot product.
p_norm: 2                         # p-value used for normalization. p=2 for L2 norm, p=1 for L1 norm and so on.

# Training related parameters
nth_epoch: 1                      # Compute validation loss in every nth_epoch
